\chapter{Future Work in Expeditionary Robots}
\label{chap:future}

\begin{center}
    \begin{minipage}{0.7\textwidth}
      \begin{small}
        How is it possible for us to know how to wisely use and protect our planet if we do not know
        what resources we have, their interactions with each other, and their interactions with humans? We need to know and fully understand our ocean so that we may thrive in harmony with nature now and in perpetuity.\\ \emph{Katy Croff Bell}
      \end{small}
    \end{minipage}
    \vspace{0.5cm}
\end{center}



Modern tools in machine learning and artificial intelligence, robotics, and planning under uncertainty have yet to be fully leveraged for ocean and environmental sciences.
In a statement to the Subcommittee on Environment of the Committee on Science, Space, and Technology of the U.S. House of Representatives in 2019\autocite{bell2019envisioning}, Dr. Katy Croff Bell identified three key areas for strategic development in ocean exploration: maximizing efficiency of discovery, developing a spectrum of exploration, and attention to big data challenges.
Robotic technologies, and roboticists, have the tools to make meaningful impact in each of these areas.
AUVs are uniquely well-suited compared to ROV or HOV technologies for underwater exploratory tasks, particularly in mapping and targeted water column surveying.
Other autonomous vehicles---such as ocean surface drones, aerial drones, or terrestrial vehicles---can support a diversity of scientific studies that can collectively link the deep ocean to the troposphere.
Modern machine learning is well-positioned to assist in complex analysis of Earth data.

To understand the ocean and Earth, it is imperative that cross-disciplinary collaborative professional, academic, and public projects are undertaken. In this chapter, the possible role of a roboticist on those teams is considered. Starting with a brief overview of challenges which arise in creating autonomous systems for expeditionary sciences, five projects that build on the work presented in this thesis are pitched; three oriented towards advancing the state of the art in robotic technologies and two rooted in open questions about geochemical distributions in natural environments outside of the deep sea. Taken together, these projects aim to illustrate the many ways in which a roboticist (both theoretical and applied) can engage with impactful research towards understanding our planet.

%%%%% 
% Overview of open challenges
%%%%%
\section{Technical Challenges and Opportunities in Expeditionary Robotics}
\label{sec:challenges}
In this thesis, an autonomy framework for deep sea hydrothermal plume charting was presented. The constituent parts of the framework---perception, prediction, and planning---each represent rich areas for further development. Here, specific technical challenges related to \emph{belief representations} and \emph{decision-making} are presented for consideration.

\subsection{Belief Representations}
Partial observability and treatment of observations is a core challenge in any expeditionary robotics problem. A belief representation useful for scientific endeavors must be able to approximate the uncertainty over scientifically-relevant quantities and make forecasts of future environmental states when trained on realistic field data. 

\paragraph{Heterogeneous observation models}
Robots used in environmental studies typically carry heterogeneous observational equipment (e.g., point chemical sensors, cameras, acoustic sonar). Optimizing sample collection to address scientific hypotheses requires fusing these different sensing modalities together and implementing complex observational models that link domain knowledge about sensor data to the state of a scientific phenomenon. Embedding expert knowledge into fused observational models, modeling sensor importance to a particular task, and reasoning across different sensors with distinct spatial and temporal resolutions\footnote{e.g.,~\cite{sarkar2014sensor}} are all active challenges. A barrier to advancing development of field-oriented science models is a lack of accessible simulation environments and education for non-science experts that sufficiently model phenomenon to a level at which reasoning about sensor models is useful. This is in contrast with other domains in robotics, like self-driving (e.g., KITTI dataset\autocite{geiger2012we}), manipulation (e.g., YCB dataset\autocite{calli2017yale}), or indoor navigation (e.g., Unity, Gazebo, or other simulators). Opportunities to develop e.g., ``geochemical playgrounds'' for simulation of oceanic and atmospheric environments would be a contribution to the community.

\paragraph{Epistemic and aleatoric uncertainty}
Reducing epistemic uncertainty of a spatiotemporal environment requires access to a model of the underlying dynamical system, or a data-driven technique that can uncover it. Extracting physically-meaningful quantities from observational data is typically performed post-expedition using computationally expensive numerical models ``tuned'' by observations. While this lends itself well to Bayesian inference formulations, it is intractable for practical decision-making. Data-driven techniques for model discovery\autocite{raissi2019physics} may be arguably more tractable, but generally suffer small-data challenges. Developing models that overcome the challenges of efficiently characterizing spatiotemporal dynamics from streaming, sparse observations would generally improve expeditionary robotics. Additionally, there is a unique opportunity to enable computation of proxies for aleatoric uncertainty, which are well-described in spatiotemporal environments with measures of chaotic motion (e.g., Lyapunov exponents) inferred from data\autocite{blanchard2019analytical}. The implication that aleatoric uncertainty can be estimated has yet to be utilized to, e.g., assess the attainable resolution of a model or set planning horizons.

\paragraph{Scientific knowledge as inductive bias}
The kernel of a GP, the loss function in a neural network, or the activation functions between layers in a deep network can all be viewed as forms of inductive bias in a learning problem. For data-driven discovery of spatiotemporal dynamics, improving sample efficiency by leveraging opportunities to inject scientific knowledge to alleviate the learning burden is an open problem. While canonical numerical models of spatiotemporal phenomena are too computationally expensive to directly incorporate into e.g., GP kernels, the physical principles that underlie these models can be more easily summarized. ``Physically-informed'' data-driven probabilistic representations, have been demonstrated outside of expeditionary robotics\autocite{raissi2019physics} and initially explored in this thesis with \PHUMES. Some additional adaptive sampling work within IPP\autocite{salam2019adaptive} shows rich opportunities for analyzing and extending these methods for larger environments and longer planning horizons.


\paragraph{Low-dimensional state embeddings}
Expressing a spatiotemporal environment completely would require an exceedingly large, high-dimensional representation. Model order reduction (MOR) techniques reduce the dimensionality of spatiotemporal systems to a set of weights and vectors that sufficiently describe patterns in the dynamics. Uncovering low-dimensional state embeddings from partially-observed expedition data is a general challenge\autocite{spantini2018inference}; uncovering a \emph{useful} embedding for a specific decision-making problem is additionally challenging\autocite{pacelli2019task}. Access to such an embedding would reduce the computational burden of representing belief in large environments for planning.

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Decision-Making}
The combination of high-dimensional and continuous state, action, and observation spaces make expeditionary science problems, formulated as POMDPs, challenging even for state-of-the-art solvers. Additional challenges related to the formulation of information-theoretic rewards for scientific hypotheses, robust planning under model-environment mismatch, and decision-interpretability are highlighted here.

\paragraph{Rollout-based planning with expensive belief models}
State-of-the-art planners for POMDP problems often make use of rollout-based planning in tree search frameworks; continuous search variables are handled using strategies such as progressive widening or scenario sampling\autocite{sunberg2018online}. However, these planners require extensive online simulations for each rollout performed. Forward-simulating the dynamics and observational models for complex, spatiotemporal phenomena can be computationally intensive, which often limits the feasible look-ahead horizon in real-time operations on computationally-limited robotic platforms.  Planners that selectively or adaptively perform expensive rollouts, automatically adjust the planning horizon based on the dynamics of the environmental system, or make use of continuous, offline planners would enable improved decision-making for expeditionary science.

\paragraph{Abstractions for planning}
Another promising direction is the development of abstract planning domains for expeditionary robotic problems. Instead of planning over a set of low-level, continuous control actions, planners could make use of high-level, abstract actions. These planning abstractions may come from human scientists or could be learned directly using recent developments in reinforcement learning and macro-action discovery\autocite{liu2017learning}.

\paragraph{Information rewards and task-driven exploration}
Due to partial observability and stochastic dynamics in spatiotemporal contexts, a decision-maker must operate with significant and often growing state uncertainty. However, not all state uncertainty impacts task performance and uniform information gathering strategies can be inefficient. Understanding the value of information for accomplishing a task is a known challenge for planning under uncertainty and this is particularly true for expeditionary robotics. Recent works that develop heuristic information rewards\autocite{flaspohler2019information} or task-driven value of information metrics\autocite{flaspohler2020belief} begin to build the tools necessary for expeditionary robotic planning.

\paragraph{Robust planning under model mismatch and uncertainty}
Scientific models, whether data-driven or based on physical principles, are always imperfect representations of a robot's environment. Model mismatch or uncertainty in key model parameters leads to discrepancies between the environmental predictions that a robot uses during planning and its real-time observations\autocite{singh2018robust}. Planning robot trajectories that entirely miss a phenomenon due to overconfidence in an incorrect model is detrimental to scientific objectives. Planners must develop policies or trajectories that are robust to model mismatch and uncertainty, or are guaranteed to perform as well as a simple, naive data collection strategy. 

\paragraph{Interpretable and operational decision-making}
Decision-making algorithms must interface with and are constrained by a variety of stakeholders, including scientists, robot operators, and engineers. For example, when deploying an AUV from an oceanographic research vessel, the decision-making algorithm must account for ship scheduling, timing delays, weather, and multi-platform operations. This requires developing flexible planners that can understand and account for these complex constraints\autocite{timmons2019automated}. Additionally, stakeholders are often concerned with robot safety and data quality. Producing plans that are interpretable for scientific and operational stakeholders is key for building trust and confidence in scientific autonomy. 



% %%%%%%%%%
% % PIKL 
% %%%%%%%%%
\section{Physically-Informed Kernel Learning}

\paragraph{Motivation}
In order to investigate scientific queries or take informative samples, a robotic vehicle must be equipped with a model.
In expeditionary science contexts, the true, continuous, underlying dynamic is generally unknown, and must be approximated from partial observations in order to form a useful belief representation to use in path planning missions.
Computing a belief from point measurements is tricky: naive treatment of the data can cause misleading conclusions to be drawn about the underlying dynamic and can ultimately lead to poor robotic behaviors.
In this thesis, \PHUMES used a Bayesian filtering framework that was placed over a simplified model of hydrothermal plume dynamics. This level of resolution was useful for predicting the location of plume masses slowly advected over a multi-hour mission to assist in sampling through an iterative, offline planning strategy.
In settings for which higher spatial or temporal resolution are necessary, however, \PHUMES may not easily extend.
For instance, in online planning settings, it would be useful to take advantage of faster inference techniques and a more highly resolved temporal model for deciding on sampling actions.

\paragraph{Proposed Project}
Gaussian processes\autocite{Rasmussen2004} (GPs) have received considerable attention for overcoming partial observability in static scalar fields for environmental sampling\autocite{zhang2007adaptive,Hitz2017,Marchant2014a}.
GPs place a distribution over continuous functions and have an analytic closed-form update suitable for streaming observations, making the framework well-suited for planning under uncertainty problems.
GPs have been used to represent spatiotemporal distributions by using specialized kernel functions that allow time to be treated as an additional dimension\autocite{Marchant2014a,garg2012learning,singh2010modeling}.
Although powerful, these kernels are difficult to define and non-intuitive to interpret, which is particularly problematic for science applications in which the model may be used not just by a robot, but by scientists in decision-making during expeditions.
Recent work embedding scientific models directly into a kernel structure\autocite{raissi2018numerical} has demonstrated serious scalability challenges (similar to \PHUMES) for online inference settings.

To address scalability and interpretability concerns, the proposed project is to develop a \emph{physically-informed kernel learner} (PIKL) that embeds scientific knowledge into the process of designing a kernel for a GP. A desirable learned kernel will be expressive and explainable with respect to a dynamics system, provide insightful uncertainty updates as real observations are drawn, and effectively represent temporal dynamics (e.g., be able to extrapolate.)

\paragraph{Background and Considerations}
Two promising architectures for PIKL are inspired by state-of-the-art machine learning/scientific machine learning research. \emph{Deep kernel learning}\autocite{wilson2015kernel} (DKL) is a neural architecture that places a GP as the final layer of an (arbitrary) artificial neural network. \emph{Knowledge-based neural ordinary differential equations}\autocite{jiahao2021knowledge} (KNODEs) train a neural ``compensator'' for expertly identified ODE models.

The advantage of using a neural architecture is one of pattern discovery---neural networks are universal approximators (given enough data), and can be used to discover expressive features that can be linked to task performance (through a loss function, for instance). In the DKL setting, a neural network is used to transform an observation space into a latent space, over which a GP with a generic kernel can be placed. The GP then provides a notion of uncertainty over the output of the architecture. The kernel can be expressed as:

\begin{equation}
	k(x_i, x_j | \theta) \longrightarrow k(h(x_i,w),h(x_j,w)|\theta,w)
\end{equation}

\noindent where $h(\cdot,\cdot)$ is a non-linear mapping given by the neural network with parameters $w$.
By maximizing the log marginal likelihood $\mathcal{L}$ of the GP, both the weights $w$ and GP parameters $\theta$ can be trained.
Using the chain rule, it can be shown that $\frac{\partial\mathcal{L}}{\partial\theta} = \frac{\partial\mathcal{L}}{\partial K}\frac{\partial K}{\partial \theta}$ and $\frac{\partial\mathcal{L}}{\partial w} = \frac{\partial\mathcal{L}}{\partial K}\frac{\partial K}{\partial h(x,w)}\frac{\partial h(x,w)}{\partial w}$ where $K$ is the covariance matrix.
Work presented in~\cite{wilson2015kernel} demonstrates that the covariance matrix $K$ can be approximated to have a form which is linear in the number of inputs to manipulate, allowing for considerable computational speed-up over typical strategies that use GPs, which is attractive for robotics applications.
Additionally, it was demonstrated in~\cite{al2017learning} that DKL can support neural architectures that learn temporal relationships and recurrent structures in data, which is relevant for modeling natural spatiotemporal environments.

To develop PIKL with a DKL backbone, one of the key design choices is the preceding neural architecture before the GP layer. In general, it would be advantageous to both use scientific knowledge of a system to pre-train PIKL in simulation and to embed scientific principles into the neural network framework. The latter is important because once out in the field, the entire architecture will be tuned from data and it would useful to place some principled constraints on the way in which the architecture changes for data efficiency and explainability reasons (e.g., useful to have a strong inductive bias). Physically-informed neural networks\autocite{raissi2019physics,lu2020extracting,mohan2019compressed} have been shown to improve data efficiency at training time in scientific machine learning works, but have yet to be demonstrated in field contexts, leaving a large opportunity for this project to experiment with and extend these architectures for practical expeditions. 

Designing the PIKL architecture requires both consideration of how it can learn an underlying function and how it can operationally be deployed during field missions. A DKL-architecture offers some amount of flexibility in its formulation for deployment experimentation. For instance, the neural layers could be ``frozen'' while a robot is underway (as in, the weights are fixed to a pre-trained value) while the kernel parameters are adjusted online to fit realistic observations as they are collected; following a deployment the entire architecture could be bulk-updated from all observations. In yet another experiment, the neural layers and the GP layer could be asynchronously updated during long-term missions. 

In contrast to DKL, KNODEs do not natively support a representation of uncertainty, but explicitly are designed to embed expert knowledge (i.e., scientific models) into a neural architecture. KNODES make use of vanilla neural ordinary differential equations\autocite{chen2018neural} (NODEs) are deep neural network models that use the intuition that the relationship between residual layers in a residual neural network (ResNet) is identical to an Euler discretization of a continuous dynamical system. This allows a chain of residual blocks in a ResNet to be equivalently viewed as an ODE initial value problem, and so a blackbox ODE solver can be used to recover the solution of the last layer. The advantage of this formulation is that the chain of residual blocks no longer needs to be rigidly defined; a differential solver can evaluate the hidden unit dynamics at arbitrary resolution based on a desired accuracy of the result. Even more generally, this means that any system which can be ``truly'' modeled as an ODE can be learned using a ResNet.

The correspondence of NODEs and classical numerical modeling makes the NODEs representation attractive for studying dynamic environmental systems. Since formulation, NODEs have been used as a forward simulator for reduced-order models of hydrodynamics\autocite{dutta2021data}, detonation in engines\autocite{koch2021data}, and turbulence forecasting\autocite{portwood2019turbulence,shankar2020learning}. Technical extensions for NODEs to learn stiff systems\autocite{kim2021stiff} and nonhomeomorphic/noncontinuous flows\autocite{dupont2019augmented}, among many other variations, have also extended its capabilities to more than just ``true'' ODE systems. As NODEs are still a general learning framework, complex dynamical systems are still difficult to recover in a data efficient way; leveraging ``expert ODEs'' within NODEs would be useful to apply a physically-informed inductive bias during training and testing, and this is what inspired KNODEs.

In brief, a KNODE is a model $\hat{f}(\x, t, \tilde{f}(\x, t), \theta)$ where $\x(t) in \mathbb{R}^n$ is an $n$-dimensional state vector for some time $t$, $\tilde{f}(\x, t)$ is expert knowledge of an environment (e.g., an ODE model of fluid flow), and $\hat{f}$ is a function approximator for a true underlying function $f$, parameterized by $\theta$. How $\tilde{f}$ is incorporated is not rigorously restricted, however in many publications leveraging the framework a linear coupling of the output of $\tilde{f}$ and a generic neural network is used. Using a neural network to compensate for unmodeled dynamics in $\tilde{f}$ is notionally similar to \emph{closure modeling} common in computational fluid dynamics, in which turbulent correlations are ``added back in'' to Reynolds- or time-averaged simulations that typically only model gross structures\autocite{durbin2018some}.

In robotics contexts, KNODEs have been utilized for augmenting model predictive controllers for multirotors, using a small number of training trajectories. In these settings, an expert model of the multirotor dynamics was used as expert knowledge\autocite{chee2022knode}. While the training and testing were performed separately in these studies, an obvious advantage of the KNODEs framework is that ``falling back'' to the expert knowledge may be a reasonable strategy (in non-control contexts; for instance in estimating the dynamics of an environment), and could enable asynchronous training of the neural layer online. 

While KNODEs effectively learn to compensate for unmodeled dynamics when expert knowledge is either incorrect or incomplete, this is not necessarily equivalent to learning an uncertainty model that can be leveraged for informative planning. For instance, a KNODE can express how much a model may be under performing in a control task, but not necessarily \emph{why} nor provide relative weights on the source of the error that could be mapped to the observational space. This leaves open an opportunity for future development. Imagined directions for extending KNODEs for use in environmental adaptive sampling could be (1) changing the coupling mechanism of a neural net and the expert knowledge and (2) placing a GP layer into a NODE formulation at the compensator. Changing the coupling mechanism between the neural network and expert knowledge will change what the neural network is compensating for. For instance, using the network to explicitly learn coefficients for the expert model is significantly different than using the network to learn a function that adjusts the entire output of the expert model. When then coupled with a GP layer at the compensator, for example, notions of uncertainty can be tied to ways in which the neural network is performing compensation and what the implications are for task performance, useful for downstream planning tasks. 


% The core question that will guide this work moving forward is \emph{how can we enable a robot to learn spatiotemporal features from streaming, partial observations in a model useful for robotic planning?}
% Towards answering this question, specific technical contributions of \textsc{PIKL} will include: a method for imposing ``physical constraints'' on a neural network, extending deep kernel learning with a novel neural architecture for spatiotemporal data handling, and extension of deep kernel learning into partially observable environments.
% Additional contributions may be contingent on what is discovered as this work matures but may include, for example, results that demonstrate that the learned kernel space is composed of ``interpretable'' features as a function of the imposed physical constraints.


% %%%%%%%%%
% % MISL
% %%%%%%%%%
\section{Measure-Invariant Subspace Learning}
% In the first of five projects pitched in this chapter, \emph{measure-invariant subspace learning} focuses on useful characteristics that a belief representation for an autonomous robot navigating in complex environments should have. 
\paragraph{Motivation}
In some environmental settings, the expert knowledge which may be available for incorporation into PIKL may be too computationally demanding to use effectively.
This especially arises in fluid flows, in which systems of PDEs that are numerically stiff are often found.
However, applying a generic belief representation over the state space for a practical environment is also expensive, due to the high dimensionality of the data (in the sense of having tens of thousands of \emph{in situ} measurements of several types of instruments, and trying to represent the state of every voxel within a 3D volume over time).

To reduce the dimensionality of the inference problem for hydrothermal plume physics in this thesis, a simplified time-averaged approximate model was used instead of high-fidelity expert model. 
When well-known simplified models for a system do not exist, or the simplified model approximation unsatisfactorily compromises on spatial or temporal resolution for a task, then leveraging numerical data reduction techniques may be useful.
Performing model order reduction (MOR) generally requires time-series samples of a generating high-fidelity model, which are then summarized as a set of ``modes'' and ``weights'' that represent energetic features of the data.
A summary of many common MOR techniques is provided in \cref{chap:related_work}.
Unfortunately, MOR techniques tend to be ill-suited for representing nonlinear systems, smoothing away local structures (e.g., spatially varying diffusion coefficients) that may be relevant for adaptive sampling tasks.
A good reduced order model would be able to reflect both global and relevant local information that is useful for computing task-relevant measures of uncertainty.

\paragraph{Proposed Project} 
One perspective on the form of a low-dimensional subspace is that is should exhibit \emph{measure invariant} qualities; that is, a statistical measure in the high-dimensional space should have correspondence to a measure in the low-dimensional one.
Measure-invariant dynamic systems are defined by the tuple $(X, \mathcal{B}, \mu, T)$ where $X$ is a set, $\mathcal{B}$ is a $\sigma$-algebra over $X$, $\mu: \mathcal{B} \longrightarrow [0,1]$ is a probability measure, and $T: X \longrightarrow X$ is a transformation which preserves $\mu$.
By the Krylov-Bogolyubov theorem\autocite{kryloff1937theorie} (which places some assumptions on the form of $X$ and $T$), an invariant probability measure is admissible and recoverable from transformations on the data.
Considerable work has shown that this theorem can be applied to samples of trajectories drawn from systems of differential equations that describe natural phenomena\autocite{stannat2011stochastic,touze2021model,vizzaccaro2022high}.
The implication of this is that a transform exists which could cast high-dimensional states onto a lower-dimensional manifold and which can preserve probabilistic measures that could be leveraged in a real-time (or practical-time) IPP sampling problem.

The proposed project is to develop a measure-invariant subspace learner (MISL) which identifies the transform (with slight modification on former notation) $T: X\rightarrow Y$ that relates measure $\mu \in \mathcal{P}(X)$ and measure $\nu \in \mathcal{P}(Y)$ such that:

\begin{equation*}
    \nu(B) = \mu(T^{-1}(B))
\end{equation*}

\noindent for all $\nu$-measurable sets $B$.

\paragraph{Background and Considerations}
Learning invariant subspaces has been proposed in several domains.
Among the most common approaches is \emph{similarity preserving embeddings} which is an implicit method that uses a kernel to map data in a Euclidean space into a Hilbert kernel space\autocite{scholkopf1997kernel}.
Designing good kernels is relatively challenging, and some argue that since the method is implicit, temporal patterns are either not captured or are not interpretable in the subspace\autocite{deng2020invariant}.
\emph{Shift-invariant representations} can be produced using sparse coding and dictionary learning methods which enable temporal trends to be captured, but fail to capture local structure in data\autocite{lewicki1999coding}.
Finally, \emph{time alignment}\autocite{deng2020invariant} aims to minimize error between pairs of samples which admits temporal trends and local structure, but requires a distance measure which may be difficult to represent or optimize to be defined.

The challenges in choosing a good formal method invite creativity in finding an invariant subspace.
One promising technique that could be targeted by the MISL project comes from within Bayesian inference.
Transport maps and optimal projectors have been used to compute subspaces suitable for solving inverse problems for dynamic systems\autocite{cui2014likelihood,spantini2018inference,spantini2015optimal}.
Computing these operators can be difficult, however work in \emph{approximate} optimal transport using Bayesian inference\autocite{spantini2018inference,spantini2019coupling,zahm2018certified,villani2008optimal,bigoni2019greedy} shows significant computational savings and advantages over other MOR techniques in terms of expressivity and data requirements.
To uncover a good transport map that has measure-invariant qualities requires identifying the statistical measures that ought to be retained.
In expeditionary science problems, the sampling objective generally is motivated by scientific hypotheses, which may focus on different features of a spatiotemporal distribution.
For example, monitoring chemical sources in an environment only requires information about where the sources are, whereas quantifying gaseous flux additionally requires information about the temporal characteristics of each source and where emitted chemicals are advected.
The ``optimal'' low-dimensional subspace to be uncovered by a map will target only those features necessary for computing the target metric.

Task-aware, or goal-aware, subspaces can be seen as a specific instance of invariant subspaces, in which, for a task-relevant measure, the lowest-dimensional invariant subspace \emph{is} task-aware.
Goal-aware learning was recently demonstrated for robotics problems\autocite{nair2020goal} in which a learner was rewarded for computing a subspace that best captured features relevant to a specific task that was to be later executed by a robot (offline and using full observations).
By using task-relevant metrics to additionally guide subspace identification through approximate map building, structure can be injected into the learning problem making it possibly more tractable and more generalizable when utilized in field settings with real data.

% In robotics, particularly in control or manipulation tasks\footnote{e.g.,~\cite{goury2018fast}}, traditional MOR techniques have been employed when the state space is fully-observable and many tasks can be executed or simulation environments are available in which to collect massive datasets.
% Learned techniques, like autoencoders\autocite{costante2018ls} or information bottlenecks\autocite{pacelli2019task}, have seen increasing popularity in robotics as a means for learning subspaces, but again are typically trained with offline regimes and with full state observations. A key consideration for \textsc{MISL} development then is considering what measures should actually be invariant in order to effectively perform a task (e.g., what task-relevant measures may look like).

%%%%%
% Predictability and Planning
%%%%%
\section{Environment Predictability and Planning}

\paragraph{Motivation}
To gather useful observations of a spatiotemporal environment for a given task in finite mission durations requires nonmyopic planning.
State of the art IPP strategies typically employ belief-space planning trees, in which a robot's belief about the environment is used to simulate potential future outcomes of action sequences in order to ``score'' (according to a reward heuristic) the single next action that leads to higher future reward\autocite{sunberg2018online,morere2018continuous,Arora2017}.
These methods typically select a fixed finite horizon $h$ over which to ``rollout'' scenarios in order to compute the score measure.
Practically, $h \leq N$ where $N$ is the total number of actions that could be executed in a single mission.
The trouble with fixing $h$ for adaptive sampling problems is that it ignores how information density of actions changes over time.
For example, typically very little information is known about an environment at the beginning of a mission, and any action is likely to be as good as any other action to take; simulating long chains of sequences at this point could be considered wasted computation.
As observations are drawn it becomes more strategic to plan trajectories in order to effectively explore or exploit knowledge.
However, if there comes a point in which the world is known very well, then simulating long trajectories at every planning step may again be wasted computation, since an open-loop plan executed to some horizon may do just as well.

The concept of \emph{reachable belief spaces}\autocite{kurniawati2008sarsop} has been used to quantify the number of belief states that can be reached from an initial starting configuration.
Recent work\autocite{flaspohler2020belief}, leverages this idea to modify the behavior of a robotic agent (selecting between closed loop and open loop trajectories) in order to save planning computation.
This idea is generally appealing for robotic adaptive sampling, however there is an additional difficulty with respect to natural spatiotemporal systems: even if the underlying function is known completely, there may be emergent stochasticity/chaotic behavior.
For instance, while the Navier Stokes equations can be written exactly, for some selections of the Reynolds number of a fluid the solution is entirely predictable (laminar flow), and for others, completely chaotic (turbulent flow).
Thus, the reachable belief space cannot be computed directly from uncertainty over the environmental model; it must also be computed with respect to the the implications that model may have about chaotic behaviors.

\paragraph{Proposed Project} 
One method for solving this problem when there is access to a model is drawing samples from a distribution of parameters of that model, and forward simulating these samples in order to characterize the stochasticity of the environment.
However, computationally, this is an intractable task for practical applications in IPP, as most sophisticated forward simulators that can capture the impacts of turbulence/stochasticity are numerically slow to solve, even in small systems.
This project proposes developing a set of learned predictability measures to be used as  meta-heuristics for nonmyopic search.
\emph{Predictability} in this case is the notion of how deterministic or chaotic a dynamic system may be.
Intuitively, characterizing the predictability of an environment will signal times or locations of increased stochasticity which may require different treatment in planning than during more predictable times or locations.
One way predictability could be used in a planning framework is in the setting of a planning horizon---optimized long-horizon exploitative trajectories may be more fruitful when predictability is high, whereas when predictability is low, any short-horizon action may be as good as another.
Another way to use predictability could be in the reward function for a planner. The utility of predictability as a reward signal would be to directly optimize trajectories that complement different, complex scientific objectives about the form of an environment (for instance, an objective to reduce uncertainty about the \emph{statistics} of turbulence in an environment may favor sampling in the most chaotic regions, whereas an objective to localize effluent sources may favor the most predictable regions).

\paragraph{Background and Considerations}
One of the critical challenges of this research is computing a notion of predictability.
For dynamical systems which can be described by differential equations, the degree to which a system can be considered predictable (alternatively, chaotic) is typically quantified by one of several measures, including \emph{Lyapunov exponents}\autocite{wolf1985determining} and the \emph{Kolmogorov-Sinai measure-theoretic entropy}\autocite{frigg2004sense}.

Kolmogorov-Sinai entropy (KSE) is a measure of trajectory divergence.
For measure-invariant systems, KSE can be computed by dividing the dynamical system into piece-wise partitions $Q = \{Q_1,...,Q_k\}$ and defining a measure of entropy on the partition $Q$ as: $H(Q) = -\sum_{m=1}^k\mu(Q_m)\log(\mu(Q_m))$.
The measure-theoretic entropy of the system with respect to a partition follows: $h_\mu(T,Q) = \lim_{N\longrightarrow\infty} \frac{1}{N}H(\vee_{n=0}^N T^{-n}Q)$, and the KSE ultimately takes the form:

\begin{equation}
    h_\mu(T) = \sup_Q h_\mu(T,Q)
\end{equation}

Lyapunov exponents, which are more commonly used in numerical analysis of dynamic systems, are also a measure of the rate of separation of infinitesimally close trajectories.
In phase space, given an initial separation of trajectories as $\delta\mathbf{Z}_0$, the rate of divergence is

\begin{equation}
    |\delta\mathbf{Z}(t)| \approx e^{\lambda t}|\delta \mathbf{Z}_0|
\end{equation}

\noindent where $\lambda$ is the Lyapunov exponent. 
In practice, there is a Lyapunov exponent associated with each dimension of the phase space.
For example, in an $n$-dimensional space $\dot{x}_i = f_i(x)$ let the Jacobian for this system take the form $J_{ij} = \frac{df_i(x)}{dx_j}\Big|_{x(t)}$.
The tangent vectors of a trajectory, $Y$, describe how a change at $x(0)$ propagates to point $x(t)$, and evolve according to $\dot{Y} = JY$.
Finally, let $\Lambda = \lim_{t\longrightarrow \infty} \frac{1}{2t}\log(Y(t)Y^T(t))$.
The eigenvalues of $\Lambda$ give the Lyapunov exponent spectrum.
The \emph{maximal Lyapunov exponent} (MLE) is the largest exponent for a given system; positive MLEs imply chaotic dynamics.

To recover KSE or Lyapunov exponents from field data requires a belief representation that natively supports their estimation. If a measure invariant subspace can be discovered, as proposed in MISL, the KSE can be computed directly. To compute Lyapunov exponents, however, requires some additional stipulations on a belief representation or learned subspace. For instance, typical MOR techniques tend to smooth away and erase instabilities in a dynamical system, making computation of Lyapunov exponents essentially impossible. Thus, when learning a descriptive subspace, preserving features in the data useful to exponent computation is necessary. Recent work has shown for low-dimensional dynamical systems that the ``instability'' subspace can be approximated from data\autocite{blanchard2019learning,blanchard2019analytical} and can explicitly support Lyapunov characterization. Applying similar restrictions placed on the learning framework in this work on a belief model like MISL could be an interesting initial starting point.




% %%%%%%
% % Mobile Geochemical Observatories
% %%%%%%
\section{Mobile Geochemical Observatories for Atmospheric Emissions}
\paragraph{Motivation}
Just as hydrothermal vents in the deep sea reveal information about crustal processes and magmatic activity, so to does the gas chemistry emitted from terrestrial volcanic vents and geothermally active fumaroles~\autocite{mcgonigle2008unmanned,smith2009volcano,fischer2015temporal}.
Several gas species, like water vapor (H$_2$O), hydrogen sulfide (H$_2$S), hydrogen chloride (HCl), carbon dioxide (CO$_2$), and sulfur dioxide (SO$_2$) can be used to predict eruptive events\autocite{smith2009volcano,fischer2015temporal,fischer2019explosions,hernandez2001carbon} as their presence and abundance indicates magmatic upwelling events.
Remote sensing of these gases e.g., from satellites, can be used to observe large emissive events, however, such techniques lack the temporal resolution and spatial sensitivity necessary for monitoring\autocite{mcgonigle2008unmanned}.
Observatories, like those operated by the United States Geological Service (USGS) use multiple sensing modalities to monitor high-risk areas\autocite{usgs2019}.
However, while GPS masts or tilt-sensors are widely used, singular geochemical sensing stations are typically reserved for the most high-risk areas due to cost\autocite{smith2009volcano}.

\paragraph{Project Proposal}
Cheap and distributable multigas sensors are in active development at Woods Hole Oceanographic Institution among other institutions\autocite{kaliszewski2021multi,stix2018using,galle2021multi}.
To get an approximate picture of the geochemical structure of venting at a volcanically dynamic site, a network of these chemical sensors could be deployed. Exhaustively instrumenting a vent field is generally not feasible\footnote{Due, for instance, in the risk placed on technicians deploying and maintaining these instruments; and the sheer scale of many environments}, however strategically using a few sensors which can be occasionally moved, or are themselves mobile and can adapt to the environment, would make deploying such a network a distinct possibility.

In this project, a team of aerial and ground vehicles for ground-to-atmospheric monitoring of gaseous volcanic emissions is envisioned for development. Equipped with small, multigas sensors, ground vehicles can be used to inspect vents and strategically monitor key productive sites over potentially long (days/weeks) periods of time, to characterize their temporal stability. Aerial teammates can provide intermittent coverage over a larger area and monitor gaseous fluxes, as well as identify regions in which an interesting vent may be likely. Coordination by the ground and air teams will ultimately yield a multi-resolution dataset of a volcanic field, which can be analyzed for e.g., long-term changes in gaseous content and estimating net gaseous and energetic output from an entire instrumented site.

\paragraph{Background and Considerations}
Flying geochemical observatories for studying volcanoes have been previously proposed and built\autocite{mcgonigle2008unmanned,stix2018using,xi2016constraining,galle2021multi}, however these systems have only been used to measure short-lived eruptive events.
Similarly, remotely-operated (or autonomous waypoint-following) ground vehicles have been used to study actively erupting sites\autocite{muscato2012volcanic}, but never in a long term context.
To date, no study has been conducted which uses an intelligent agent to characterize long-term characteristics in geothermal volcanic fields.
Such a system would provide insight about volcanic emissions that would otherwise be difficult or impossible to retrieve with current sensing modalities.

The problem of long-term monitoring in dynamic environments poses significant research questions for both intelligent sampling development and scientific machine learning. In general, learning the underlying dynamic of a spatiotemporally-evolving system is a hard problem; exploiting it in order to answer varied scientific queries adds further complexity; and adding multi-fidelity sensing and heterogeneous teams makes the problem an interesting avenue for algorithmic research.
Functionally, this is a potent planning under uncertainty problem.
To begin to approach designing an autonomy framework for this problem, inspiration in other academic fields may prove useful. For instance, in sea-surface temperature research, satellite data and \emph{in situ} measurements from buoys are often combined into predictive models with notions of uncertainty\autocite{babaee2020multifidelity}. Application of these techniques outside of ocean environments would be scientifically novel, let alone potentially useful for planning. In planning, state-of-the-art results in multirobot coordination in search and rescue contexts, in which intermittent communication, collaborative mapping, and heterogenous capabilities are considered, may similarly find a novel application in volcanic monitoring\autocite{rizk2019cooperative,queralta2020collaborative}.



% %%%%%%
% % Estuary Methane
% %%%%%%
\section{Modeling Anthropogenic Methane in Estuaries}
\paragraph{Motivation}
Coastal zones are found at the interface of land and ocean environments, and host the most productive ecosystems on Earth, largely due to a diversity of physical and geochemical processes.
The complexity of carbon cycling in these environments makes characterizing and modeling atmospheric flux particularly challenging.
For example, rivers are considered sources of methane and carbon dioxide, which are outgassed during turbulent events\autocite{cole2007plumbing, stanley2016ecology}; however salt marshes can be considered a carbon sink through biological activity\autocite{cai2011estuarine}.
When anthropogenic influences are examined with respect to these environments, there are further complications.
Estuaries and rivers receive a considerable amount of treated and untreated wastewater.
While untreated wastewater is obviously problematic, even treated wastewater can be hiding dangerous pollutants.
In illustration, consider a study of the Wareham River in Massachusetts\footnote{savebuzzardsbay.org/embayments/wareham-river/} in which a 1.56 million-gallon-per-day biological nutrient removal waterwater control center cleans and dumps water.
The feedstock for bacteria in one of the treatment stages is methanol. When that methanol is not completely digested by the bacteria, it is carried by the cleaned wastewater into the river. Significant methane plumes were confirmed to be present in the river near the wastewater outfall, and hypothesized to be rapidly ventilated or digested within the estuary\autocite{preston2019adaptive}.
This is alarming as methane is a potent greenhouse gas, and disrupting natural food chains in an estuary has compounding impacts on overall river health; it is also alarming because this is an essentially ``invisible'' problem as the water meets regulatory cleanliness standards and methane is an odorless, colorless gas.
Major facets of research on estuarine waters influenced by wastewater include characterizing the impacts of synthetic materials (e.g., antibiotics\autocite{roberts2006occurrence}), increased organic materials (e.g., fertilizers and treatment feedstock\autocite{valiela2016eutrophication}), and urban developments (e.g., stormwater run-off\autocite{geedicke2018urban}).


\paragraph{Proposed Project}
It is imperative that monitoring solutions and models for biogeochemical transport of methane and other greenhouse gases and pollutants that enter coastal estuaries be developed for effective policy-based interventions at wastewater treatment plants and other anthropogenic outfalls. Such a systems would characterize the fate of geochemicals: where they are transported to aqueously, how much may ventilate into the atmosphere, and what is consumed by biological processes. To assist in developing these models, high-resolution measurements of dissolved gases, particulates, and other tracers (e.g., salinity, temperature) are necessary. 

Robotic platforms, from small underwater vehicles to surface vehicles to aerial vehicles, could all carry instrumentation that looks at the river-to-atmosphere continuum while carrying \emph{in situ} equipment. The distinct advantage to using robotic platforms in this setting is related to the character of the environment; some river systems may only be practically navigable by small (kayak-sized) water craft, requiring scientists or technicians to perform relatively labor-intensive sample collection if they were to do this themselves. As collecting data over multiple days, weeks, and seasons would be beneficial, using robotic technologies that can execute consistent tasks with minimal supervision over long monitoring horizons would significantly change the paradigm of estuary sampling today. This project envisions the development of robotic monitoring tools for estuary science, and automated data science tools for processing the big data that is generated by such studies.


\paragraph{Background and Considerations}
Estuarine research has historically used numerical models of fluid flows\autocite{geyer2014estuarine} (of varying resolution) and sparse observations of pollutants (e.g., bottle samples)\autocite{rheuban2019quantifying} to generate estimates of tracer transport and fate. \emph{In situ} sensors suitable for these studies have yet to be fully leveraged for geochemical estuarine research, and they represent a large departure from classical approaches. Hesitancy in part comes from ``data paralysis'' of going from a few sparse measurements to tens of thousands of observations, as typical methods used to invert fluid models may be brittle or computationally intractable to perform over so much data. Moreover, there is not yet an agreed standard for parsing bulk \emph{in situ} observations of estuarine chemicals. A roboticist may be well-suited to assist in these areas as fluency in developing and interpreting belief representations (data summaries) is a natural tool to address these issues. Algorithmically, similar challenges as other expeditionary contexts persist---namely dealing with partial observations of spatiotemporal environments, making this not just a straightforward application of out-of-the-box methods. 


\section{Looking Ahead}
Expeditionary science motivates a set of interesting robotics, modeling, and decision-making problems that are not well-addressed by current state-of-the-art methods. There is increasing need to enable better \emph{in situ} methodologies for monitoring and characterizing large spatiotemporal environments as accelerated climate change transforms delicate carbon budgets, ecosystem networks, and weather patterns. Robotic technologies, both theoretical and applied, can play a transformative role in understanding these evolving trends and assessing policy interventions. %Novel developments towards the challenges and project settings discussed here may have constructive and complementary effects in other application spaces, as many domains, such as material discovery and robotic manipulation, have overlapping challenges and opportunities. 

% It cannot be understated the importance of collaborative teaming with domain experts across the environmental domains and robotics. Detailed understanding of instruments and operational constraints, introduction to commonly used numerical models (or other scientific approximations), and access to the field are all areas in which scientists excel; roboticists bring practical and algorithmic tools that assist with data management, analysis, and planning under uncertainty that stand to transform field-going paradigms. To interact collaboratively means to approach a problem with humility (do not be a hammer looking for a nail), make efforts to understand one another's professional ``language'' and give one another grace and patience, be able to compromise, and keep the ultimate goals---collect data, do good science---in mind. 